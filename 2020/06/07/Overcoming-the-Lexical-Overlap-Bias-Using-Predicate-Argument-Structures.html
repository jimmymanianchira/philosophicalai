<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Overcoming The Lexical Overlap Bias Using Predicate Argument Structures | Philosophical AI</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Overcoming The Lexical Overlap Bias Using Predicate Argument Structures" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Reviewing: Overcoming the Lexical Overlap Bias Using Predicate-Argument Structures" />
<meta property="og:description" content="Reviewing: Overcoming the Lexical Overlap Bias Using Predicate-Argument Structures" />
<link rel="canonical" href="https://jimmymanianchira.github.io/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html" />
<meta property="og:url" content="https://jimmymanianchira.github.io/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html" />
<meta property="og:site_name" content="Philosophical AI" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-07T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://jimmymanianchira.github.io/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html"},"description":"Reviewing: Overcoming the Lexical Overlap Bias Using Predicate-Argument Structures","@type":"BlogPosting","url":"https://jimmymanianchira.github.io/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html","headline":"Overcoming The Lexical Overlap Bias Using Predicate Argument Structures","dateModified":"2020-06-07T00:00:00-05:00","datePublished":"2020-06-07T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/philosophicalai/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jimmymanianchira.github.io/philosophicalai/feed.xml" title="Philosophical AI" /><link rel="shortcut icon" type="image/x-icon" href="/philosophicalai/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Overcoming The Lexical Overlap Bias Using Predicate Argument Structures | Philosophical AI</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Overcoming The Lexical Overlap Bias Using Predicate Argument Structures" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Reviewing: Overcoming the Lexical Overlap Bias Using Predicate-Argument Structures" />
<meta property="og:description" content="Reviewing: Overcoming the Lexical Overlap Bias Using Predicate-Argument Structures" />
<link rel="canonical" href="https://jimmymanianchira.github.io/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html" />
<meta property="og:url" content="https://jimmymanianchira.github.io/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html" />
<meta property="og:site_name" content="Philosophical AI" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-07T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://jimmymanianchira.github.io/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html"},"description":"Reviewing: Overcoming the Lexical Overlap Bias Using Predicate-Argument Structures","@type":"BlogPosting","url":"https://jimmymanianchira.github.io/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html","headline":"Overcoming The Lexical Overlap Bias Using Predicate Argument Structures","dateModified":"2020-06-07T00:00:00-05:00","datePublished":"2020-06-07T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://jimmymanianchira.github.io/philosophicalai/feed.xml" title="Philosophical AI" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/philosophicalai/">Philosophical AI</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/philosophicalai/about/">About Me</a><a class="page-link" href="/philosophicalai/search/">Search</a><a class="page-link" href="/philosophicalai/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Overcoming The Lexical Overlap Bias Using Predicate Argument Structures</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-07T00:00:00-05:00" itemprop="datePublished">
        Jun 7, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><strong>Reviewing: Overcoming the Lexical Overlap Bias Using Predicate-Argument Structures</strong></p>

<p>Starting with, this is a must read for anyone using transformer models (Bert, Xlnet) for solving NLP problems. It is no big secret that the transformer babies are kicking ass in pretty much all NLP scoreboards. But does kicking ass in nlp scoreboards equate to real life applicability. For last year or so, I have been here and there testing transformers on various other domains. And I will be honest, I was impressed but not all the time. Model makes a lot of mistakes that it seems counterintuitive to what they should have learned. This was a real problem and I searched for a solution and that’s when I came upon this paper. This paper claims it will help me with my problems. So, let’s dig deep.</p>

<p>In the “Introduction” itself the paper states this obvious fact-</p>

<p><em>“For instance, given the premise “Neil Armstrong was the first man who landed on the Moon”, the model may recognize the sentence “Moon was the first man who landed on the Neil Armstrong” as an entailing hypothesis or a plausible ending because it has a high lexical overlap with the premise.”</em></p>

<p>I understood it wasn’t just me alone getting transferability issues with Textual Entailment models. That was a ‘whew’! :P</p>

<p>Paper goes to compare itself with existing solutions which tries to address this problem and they all require a few things-</p>

<p><em>“new models or training procedures and the model’s complexity remains unchanged.”</em></p>

<p><strong>Experimental Setup</strong></p>

<p>Let’s discuss on the experimental setup which they used to check if they could overcome the lexical Bias.</p>

<p>They are evaluating 2 NLP Tasks-</p>

<p>1)  SWAG- “<em>Given a premise that is a partial description about a situation, GCI is the task of reasoning about what is happening and predicting what might come next. SWAG models this task as a multiple-choice answer selection, in which the premise is given and the correct and three incorrect endings are presented as candidate answers.”</em></p>

<p>” <em>We created three different adversarial datasets based on the SWAG development set for evaluating the lexical overlap bias. These datasets evaluate the model’s understanding of (1) syntactic variations, (2) antonym relations, and (3) named entities in the presence of high lexical overlap</em>”</p>

<p>Let me be honest with you, I haven’t done much work with Swag and the task seems very interesting from a NLP perspective. However, I haven’t been able to visualize, how any pretrained models from SWAG can be used for solving upstream business problems. But I am always open to new ideas that challenges my beliefs and in search for it.</p>

<p>2)  Natural Language Inference. Given a premise and a hypothesis, NLI is the task of determining whether the hypothesis entails, contradicts, or is neutral to the premise.</p>

<p>Now to overcome the Lexical Bias they wanted an evaluation dataset. Both the original SWAG &amp; MultiNLI dataset have these biases, so evaluating on their test datasets won’t be useful.</p>

<p>So, for SWAG, they created 3 evaluation datasets. According to them-</p>

<p>“<em>These datasets evaluate the model’s understanding of (1) syntactic variations, (2) antonym relations, and (3) named entities in the presence of high lexical overlap.”</em></p>

<p>For NLI they are using an existing available dataset. Heuristic Analysis for NLI Systems (HANS) dataset. This was a welcome surprise to me.</p>

<p><strong>Their Approach</strong></p>

<p>If you have noticed earlier, I had mentioned that their approach does not involve any change in the model or any other complexity. So, the only way they could solve this is using data augmentation. And if this problem can be solved like this, it’s a big win for all of us as this can be applied for any dataset of our choice.</p>

<p>They augment the training set by introducing predicate-argument structure using the ProbBank-style semantic role labelling model of Shi and Lin (2019) , which has the state-of-the-art results on the CoNLL-2009 dataset, to get predicate-argument structures.. This is how data example will look after augmentation-</p>

<p><img src="https://jimmymanianchira.github.io/philosophicalai/assets/img/2020-06-07-Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures/media/image1.png" alt="" /></p>

<p><strong>Models Used for Setup</strong></p>

<p>They use bert, xlnet and Roberta models available from huggingface and then finetuned the models on Swag &amp; MultiNLI Dataset for the GCI &amp; NLI task respectively.</p>

<p><strong>Results</strong></p>

<p><img src="https://jimmymanianchira.github.io/philosophicalai/assets/img/2020-06-07-Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures/media/image2.png" alt="" /></p>

<p>1)  Data augmentation is causing a substantial increase in “non-entailment” case for BERT &amp; XLNET. for Roberta accuracy seems to have gone down a bit.</p>

<p>2)  Clearly Roberta seems to be the most robust in case of MNLI with &amp; without data augmentation. Time to use Roberta more.</p>

<p><img src="https://jimmymanianchira.github.io/philosophicalai/assets/img/2020-06-07-Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures/media/image3.png" alt="" /></p>

<p>3)  The results are more clear in the case of Swag Dataset. Augmentation has increased accuracy for all 3 evaluation datasets. Here, also RobertA is dominating the pack.</p>

<p>4)  It is to be concluded that models trained on MNLI are tending to have less issues when compared to the Swag ones. So, it seems that finetuning can have significant impact on the model’s understanding of natural language.</p>

<p>5)  The results on the HANS dataset can vary by a large margin using different random seeds during fine-tuning, e.g., BERT accuracy on the lexical overlap subset can vary from 6% to 54%. This is a bit disappointing that random seeds can have such a significant impact. It qualifies the need for more dissection of BERT models.</p>

<p>6)  They tried SRL using a different model (OPENIE which is less accurate). In this case also SRL resulted in an improvement in accuracy.</p>

<p>7)  They alse tested the augmentation on Roberta-large. Here also, there was an improvement when they checked on Adversial SWAG datasets.</p>

<p>8)  Luckily adding augmentation on test data did not yield any difference. It would have been a pain if it was the alternative.</p>

<p><strong>Key Takeaways-</strong></p>

<p>1)  We need to get more understanding of Transformer Models. We now seem to have research papers conflicting each other on their understanding of Transformer Models</p>

<p>2)  Better training and evaluation datasets are needed for NLP. SuperGlue is a big win, but we need more.</p>

<p>3)  For now, I am of the opinion that transformer models will need significant finetuning before they can adapt to a business scenario.</p>

  </div><a class="u-url" href="/philosophicalai/2020/06/07/Overcoming-the-Lexical-Overlap-Bias-Using-Predicate-Argument-Structures.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/philosophicalai/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/philosophicalai/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/philosophicalai/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Where Philosophy meets AI</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
